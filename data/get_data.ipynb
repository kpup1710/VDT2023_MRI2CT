{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import random\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMG_EXTENSIONS = ['.jpg', '.JPG', '.jpeg', '.JPEG',\n",
    "                  '.png', '.PNG', '.ppm', '.PPM', '.bmp', '.BMP']\n",
    "\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)\n",
    "\n",
    "\n",
    "def get_paths_from_images(path):\n",
    "    assert os.path.isdir(path), '{:s} is not a valid directory'.format(path)\n",
    "    images = []\n",
    "    for dirpath, _, fnames in sorted(os.walk(path)):\n",
    "        for fname in sorted(fnames):\n",
    "            if is_image_file(fname):\n",
    "                img_path = os.path.join(dirpath, fname)\n",
    "                images.append(img_path)\n",
    "    assert images, '{:s} has no valid image file'.format(path)\n",
    "    return sorted(images)\n",
    "\n",
    "\n",
    "def augment(img_list, hflip=True, rot=True, split='val'):\n",
    "    # horizontal flip OR rotate\n",
    "    hflip = hflip and (split == 'train' and random.random() < 0.5)\n",
    "    vflip = rot and (split == 'train' and random.random() < 0.5)\n",
    "    rot90 = rot and (split == 'train' and random.random() < 0.5)\n",
    "\n",
    "    def _augment(img):\n",
    "        if hflip:\n",
    "            img = img[:, ::-1, :]\n",
    "        if vflip:\n",
    "            img = img[::-1, :, :]\n",
    "        if rot90:\n",
    "            img = img.transpose(1, 0, 2)\n",
    "        return img\n",
    "\n",
    "    return [_augment(img) for img in img_list]\n",
    "\n",
    "\n",
    "def transform2numpy(img):\n",
    "    img = np.array(img)\n",
    "    img = img.astype(np.float32) / 255.\n",
    "    if img.ndim == 2:\n",
    "        img = np.expand_dims(img, axis=2)\n",
    "    # some images have 4 channels\n",
    "    if img.shape[2] > 3:\n",
    "        img = img[:, :, :3]\n",
    "    return img\n",
    "\n",
    "\n",
    "def transform2tensor(img, min_max=(0, 1)):\n",
    "    # HWC to CHW\n",
    "    img = torch.from_numpy(np.ascontiguousarray(\n",
    "        np.transpose(img, (2, 0, 1)))).float()\n",
    "    # to range min_max\n",
    "    img = img*(min_max[1] - min_max[0]) + min_max[0]\n",
    "    return img\n",
    "\n",
    "\n",
    "# implementation by numpy and torch\n",
    "# def transform_augment(img_list, split='val', min_max=(0, 1)):\n",
    "#     imgs = [transform2numpy(img) for img in img_list]\n",
    "#     imgs = augment(imgs, split=split)\n",
    "#     ret_img = [transform2tensor(img, min_max) for img in imgs]\n",
    "#     return ret_img\n",
    "\n",
    "\n",
    "# implementation by torchvision, detail in https://github.com/Janspiry/Image-Super-Resolution-via-Iterative-Refinement/issues/14\n",
    "totensor = torchvision.transforms.ToTensor()\n",
    "hflip = torchvision.transforms.RandomHorizontalFlip()\n",
    "def transform_augment(img_list, split='val', min_max=(0, 1)):    \n",
    "    imgs = [totensor(img) for img in img_list]\n",
    "    if split == 'train':\n",
    "        imgs = torch.stack(imgs, 0)\n",
    "        imgs = hflip(imgs)\n",
    "        imgs = torch.unbind(imgs, dim=0)\n",
    "    ret_img = [img * (min_max[1] - min_max[0]) + min_max[0] for img in imgs]\n",
    "    return ret_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import lmdb\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "# import data.util as Util\n",
    "\n",
    "\n",
    "class LRHRDataset(Dataset):\n",
    "    def __init__(self, dataroot, datatype, l_resolution=16, r_resolution=128, split='train', data_len=-1, need_LR=False):\n",
    "        self.datatype = datatype\n",
    "        self.l_res = l_resolution\n",
    "        self.r_res = r_resolution\n",
    "        self.data_len = data_len\n",
    "        self.need_LR = need_LR\n",
    "        self.split = split\n",
    "\n",
    "        if datatype == 'lmdb':\n",
    "            self.env = lmdb.open(dataroot, readonly=True, lock=False,\n",
    "                                 readahead=False, meminit=False)\n",
    "            # init the datalen\n",
    "            with self.env.begin(write=False) as txn:\n",
    "                self.dataset_len = int(txn.get(\"length\".encode(\"utf-8\")))\n",
    "            if self.data_len <= 0:\n",
    "                self.data_len = self.dataset_len\n",
    "            else:\n",
    "                self.data_len = min(self.data_len, self.dataset_len)\n",
    "        elif datatype == 'img':\n",
    "            self.sr_path = get_paths_from_images(\n",
    "                '{}/sr_{}_{}'.format(dataroot, l_resolution, r_resolution))\n",
    "            self.hr_path = get_paths_from_images(\n",
    "                '{}/hr_{}'.format(dataroot, r_resolution))\n",
    "            if self.need_LR:\n",
    "                self.lr_path = get_paths_from_images(\n",
    "                    '{}/lr_{}'.format(dataroot, l_resolution))\n",
    "            self.dataset_len = len(self.hr_path)\n",
    "            if self.data_len <= 0:\n",
    "                self.data_len = self.dataset_len\n",
    "            else:\n",
    "                self.data_len = min(self.data_len, self.dataset_len)\n",
    "        else:\n",
    "            raise NotImplementedError(\n",
    "                'data_type [{:s}] is not recognized.'.format(datatype))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_HR = None\n",
    "        img_LR = None\n",
    "\n",
    "        if self.datatype == 'lmdb':\n",
    "            with self.env.begin(write=False) as txn:\n",
    "                hr_img_bytes = txn.get(\n",
    "                    'hr_{}_{}'.format(\n",
    "                        self.r_res, str(index).zfill(5)).encode('utf-8')\n",
    "                )\n",
    "                sr_img_bytes = txn.get(\n",
    "                    'sr_{}_{}_{}'.format(\n",
    "                        self.l_res, self.r_res, str(index).zfill(5)).encode('utf-8')\n",
    "                )\n",
    "                if self.need_LR:\n",
    "                    lr_img_bytes = txn.get(\n",
    "                        'lr_{}_{}'.format(\n",
    "                            self.l_res, str(index).zfill(5)).encode('utf-8')\n",
    "                    )\n",
    "                # skip the invalid index\n",
    "                while (hr_img_bytes is None) or (sr_img_bytes is None):\n",
    "                    new_index = random.randint(0, self.data_len-1)\n",
    "                    hr_img_bytes = txn.get(\n",
    "                        'hr_{}_{}'.format(\n",
    "                            self.r_res, str(new_index).zfill(5)).encode('utf-8')\n",
    "                    )\n",
    "                    sr_img_bytes = txn.get(\n",
    "                        'sr_{}_{}_{}'.format(\n",
    "                            self.l_res, self.r_res, str(new_index).zfill(5)).encode('utf-8')\n",
    "                    )\n",
    "                    if self.need_LR:\n",
    "                        lr_img_bytes = txn.get(\n",
    "                            'lr_{}_{}'.format(\n",
    "                                self.l_res, str(new_index).zfill(5)).encode('utf-8')\n",
    "                        )\n",
    "                img_HR = Image.open(BytesIO(hr_img_bytes)).convert(\"RGB\")\n",
    "                img_SR = Image.open(BytesIO(sr_img_bytes)).convert(\"RGB\")\n",
    "                if self.need_LR:\n",
    "                    img_LR = Image.open(BytesIO(lr_img_bytes)).convert(\"RGB\")\n",
    "        else:\n",
    "            img_HR = Image.open(self.hr_path[index]).convert(\"RGB\")\n",
    "            img_SR = Image.open(self.sr_path[index]).convert(\"RGB\")\n",
    "            if self.need_LR:\n",
    "                img_LR = Image.open(self.lr_path[index]).convert(\"RGB\")\n",
    "        if self.need_LR:\n",
    "            [img_LR, img_SR, img_HR] = transform_augment(\n",
    "                [img_LR, img_SR, img_HR], split=self.split, min_max=(-1, 1))\n",
    "            return {'LR': img_LR, 'HR': img_HR, 'SR': img_SR, 'Index': index}\n",
    "        else:\n",
    "            [img_SR, img_HR] = transform_augment(\n",
    "                [img_SR, img_HR], split=self.split, min_max=(-1, 1))\n",
    "            return {'HR': img_HR, 'SR': img_SR, 'Index': index}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
